{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_data1 = pd.read_csv('CV_tweets.csv')\n",
    "tweet_data2 = pd.read_csv('CV_tweets_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lagos, Nigeria                  698\n",
       "Nigeria                         495\n",
       "Abuja, Nigeria                  141\n",
       "Lagos                           106\n",
       "Accra, Ghana                     57\n",
       "Ibadan, Nigeria                  46\n",
       "Abuja                            43\n",
       "Port Harcourt, Nigeria           42\n",
       "Ghana                            34\n",
       "Lagos Nigeria                    31\n",
       "Kano, Nigeria                    26\n",
       "Kaduna, Nigeria                  24\n",
       "lagos                            23\n",
       "Lagos,Nigeria                    22\n",
       "Nigeria                          21\n",
       "Ilorin, Nigeria                  21\n",
       "Uganda                           20\n",
       "nigeria                          19\n",
       "Ikeja, Nigeria                   18\n",
       "PA                               17\n",
       "Jos, Nigeria                     16\n",
       "Lagos, Nigeria.                  15\n",
       "Benin-City, Nigeria              15\n",
       "Greater Accra, Ghana             15\n",
       "Lagos                            14\n",
       "Pacific Northwest                14\n",
       "Enugu, Nigeria                   13\n",
       "Ibadan                           13\n",
       "NIGERIA                          12\n",
       "Calabar, Nigeria                 12\n",
       "                               ... \n",
       "Space Station, Afrika             1\n",
       "Ikeja Lagos Nigeria               1\n",
       "CITY OF YELLOW BUSSES             1\n",
       "TemaðŸ¤«                             1\n",
       "Anambra                           1\n",
       "akure                             1\n",
       "Karu, Nigeria                     1\n",
       "LAGOS NIGERIA                     1\n",
       "Lafia, Nasarawa State             1\n",
       "Abeokuta Nigeria                  1\n",
       "Ogun                              1\n",
       "Emirate plaza U/rimi kaduna       1\n",
       "BK                                1\n",
       "InterChange                       1\n",
       "Tarauni local govt kano           1\n",
       "OK                                1\n",
       "Republique du niger               1\n",
       "OYO state                         1\n",
       "Lagos, ikeja                      1\n",
       "Somewhere                         1\n",
       "no                                1\n",
       "Bauch, Nigeria                    1\n",
       "Ghana/Kumasi                      1\n",
       "Nah                               1\n",
       "Mx city                           1\n",
       "Upsilon                           1\n",
       "Lagos island                      1\n",
       "Abuja/Lagos, Nigeria              1\n",
       "delta state                       1\n",
       "Kano katsina                      1\n",
       "Name: Location, Length: 553, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data1['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect major tweets containing nigeria related places\n",
    "ng_tweets_data1 = tweet_data1[tweet_data1['Location'].str.contains('Nigeria|Lagos|Abuja|lagos|nigeria',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3839"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the two Tweets dataframes into one\n",
    "frames = [ng_tweets_data1,tweet_data2]\n",
    "combined_ng_tweets = pd.concat(frames,axis=0)\n",
    "len(combined_ng_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only Tweet column\n",
    "ng_tweets = combined_ng_tweets['Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                  3839\n",
       "unique                                                 3493\n",
       "top       b'Repeat after me...\\n\\n- I will not forward W...\n",
       "freq                                                      6\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see deails about the data. Note the presence of duplicates\n",
    "ng_tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3493"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get only the unique tweets and convert to list\n",
    "ng_tweets= ng_tweets.unique().tolist()\n",
    "len(ng_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'I wish I could just be Corona virus ,, traveling from one country to another without transport money ,,chai life for sweet die'\",\n",
       " 'b\"The Corona virus is a man made virus which was created to curtail population growth ...\\\\nCall this a conspiracy theory but that\\'s the truth and the sheep is always ignorant of the truth #coronavirusnigeria #COVID19Nigeria #coronavirus #coronavirusinlagos\"',\n",
       " \"b'@lilcel4 That\\\\xe2\\\\x80\\\\x99s how una dey catch all this Yama Yama \\\\xf0\\\\x9f\\\\xa6\\\\xa0 corona virus'\",\n",
       " \"b'Ein own emergency go pass person wei get Corona and Virus https://t.co/XKNIm7sPo8'\",\n",
       " \"b'Corona virus is real, no lapse am o'\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 tweets\n",
    "ng_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tweet(tweet):\n",
    "    #remove twitter usernames e.g. @user\n",
    "    processed_tweet = re.sub(r\"@[A-Za-z0-9]*\",\"\", tweet)\n",
    "    #remove encoded charaacters \\\\xe2\n",
    "    processed_tweet = re.sub(r\"\\\\x\\S+\", \" \" ,processed_tweet)\n",
    "    #remove the starting bytes symbol (b) and the quotes\n",
    "    processed_tweet = re.sub(r\"^b'|^b\\\"|'$|\\\"$\", \" \", processed_tweet)\n",
    "    #remove links\n",
    "    processed_tweet = re.sub(r\"\\w+:\\/\\/\\S+\", \" \", processed_tweet)    \n",
    "    '''processed_tweet = processed_tweet.lower()\n",
    "    tweet_words = processed_tweet.split()\n",
    "    filtered_tweet = []\n",
    "    for word in tweet_words:\n",
    "        if word not in stop_words and word not in string.punctuation:\n",
    "            filtered_tweet.append(word)\n",
    "    cleaner_tweet=' '.join(filtered_tweet)\n",
    "    cleaned_tweets.append(cleaner_tweet)'''\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the two analyzers to used; vader and TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentiment(tweet):\n",
    "    \"\"\"get the sntiment of each tweet using the two algorithms \"\"\"\n",
    "    global textblob_pos \n",
    "    global textblob_neg \n",
    "    global textblob_neu \n",
    "    global vader_pos \n",
    "    global vader_neg \n",
    "    global vader_neu \n",
    "    sentiment_dict = analyzer.polarity_scores(tweet)\n",
    "    if sentiment_dict['compound'] >=0.05:\n",
    "        vader_pos += 1        \n",
    "    elif sentiment_dict['compound']<=-0.05:\n",
    "        vader_neg +=1\n",
    "\n",
    "    else:\n",
    "        vader_neu += 1\n",
    "\n",
    "    tb = TextBlob(tweet)\n",
    "    if tb.sentiment.polarity > 0:\n",
    "        textblob_pos += 1\n",
    "\n",
    "    elif tb.sentiment.polarity == 0:\n",
    "        textblob_neu += 1\n",
    "    else:\n",
    "        textblob_neg += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-181505fc751e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m  \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mng_tweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcleaned_tweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcheck_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_tweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "#variables to hold the count of each sentiment\n",
    "textblob_pos = 0\n",
    "textblob_neg = 0\n",
    "textblob_neu = 0\n",
    "vader_pos = 0\n",
    "vader_neg = 0\n",
    "vader_neu = 0\n",
    "\n",
    "for  tweet in ng_tweets:\n",
    "    cleaned_tweet = clean_tweet(tweet)\n",
    "    check_sentiment(cleaned_tweet, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
